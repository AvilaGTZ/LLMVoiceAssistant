#include "assistantUtils.h"
#include "speechRecognition.h"
#include "llmInference.h"
#include "common.h"
#include "whisper.h"  // Whisper library
#include "llama.h"    // LLaMA library
#include "sampling.h"

using namespace assistantUtils;

int main() {
    std::cout << "Starting Voice Assistant..." << std::endl;

    // ðŸ“ Paths are defined in buildAssistant.sh
    const char * whisper_model_path = WHISPER_MODEL_PATH;
    const char * llama_model_path = LLAMA_MODEL_PATH;
    std::string audio_file_path = AUDIO_FILE_PATH;

    /*Create the speech recognition instance to transform thw audio into text(string)*/
    assistantAsr::SpeechRecongnition speachRecognition(whisper_model_path);
    std::vector<float> audioData;
    speachRecognition.getAudioDataFromWav(audio_file_path, audioData);
    std::string whisperTranscription = speachRecognition.generateTranscript(audioData);

    /*Create the llm inference instance to pass the text prompt*/
    assistantLlm::LlmInference llmInference(llama_model_path);
    std::string llamaPrompt = llmInference.convertToLlamaPrompt(whisperTranscription);
    std::string llamaResponse = llmInference.generateInference_SAMPLER(llamaPrompt);

    /*Display the results*/
    std::cout << "\nWhisper transcription:\n" << whisperTranscription << std::endl;
    std::cout << "\nPrompt:\n" << llamaPrompt << std::endl;
    std::cout << "\nResponse generated by LLaMA:\n" <<llamaResponse << std::endl;

    return 0;
}
